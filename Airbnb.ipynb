{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.6 109.6 133.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dc_listings = pd.read_csv('F:/education/data quest/machine learning sessions/Airbnb/dc_airbnb.csv')\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "\n",
    "def predict_price_total(new_listing):\n",
    "    temp_df = dc_listings.copy()\n",
    "    ## Complete the function.\n",
    "    temp_df['distance']=temp_df['accommodates'].apply(lambda x: np.abs(x-new_listing))\n",
    "    temp_df=temp_df.sort_values('distance')\n",
    "    k=temp_df.iloc[0:5]['price'].mean()\n",
    "    return k\n",
    "acc_one = predict_price_total(1)\n",
    "acc_two = predict_price_total(2)\n",
    "acc_four = predict_price_total(4)\n",
    "print(acc_one,acc_two,acc_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3696    130.2\n",
      "142     349.6\n",
      "182     142.6\n",
      "1678    130.2\n",
      "2173    130.2\n",
      "1716    142.6\n",
      "2530    130.2\n",
      "2329    245.8\n",
      "2042    130.2\n",
      "3266    130.2\n",
      "3077    130.2\n",
      "3169    142.6\n",
      "98      225.8\n",
      "2659    130.2\n",
      "3523    130.2\n",
      "931     130.2\n",
      "572     130.2\n",
      "1924    146.0\n",
      "1273    142.6\n",
      "224     142.6\n",
      "106     146.0\n",
      "1127     53.4\n",
      "845     146.0\n",
      "1413    130.2\n",
      "3705    276.6\n",
      "938     146.0\n",
      "741     276.6\n",
      "3498    146.0\n",
      "2066    130.2\n",
      "1272    130.2\n",
      "        ...  \n",
      "150     142.6\n",
      "430     130.2\n",
      "1596    801.8\n",
      "366     146.0\n",
      "1714    130.2\n",
      "2475    130.2\n",
      "1710    130.2\n",
      "1305     53.4\n",
      "749     142.6\n",
      "49      130.2\n",
      "802     130.2\n",
      "1046    142.6\n",
      "895     142.6\n",
      "3313     53.4\n",
      "2499    146.0\n",
      "2700    142.6\n",
      "3420    142.6\n",
      "2553    276.6\n",
      "942     146.0\n",
      "1769    146.0\n",
      "2005    245.8\n",
      "59      130.2\n",
      "1817    130.2\n",
      "1248    146.0\n",
      "2419    142.6\n",
      "954     245.8\n",
      "3186    130.2\n",
      "2633    130.2\n",
      "3563    130.2\n",
      "1520    146.0\n",
      "Name: predicted_price, Length: 931, dtype: float64 3696     70.0\n",
      "142     300.0\n",
      "182     210.0\n",
      "1678    128.0\n",
      "2173     79.0\n",
      "1716    115.0\n",
      "2530    100.0\n",
      "2329    189.0\n",
      "2042     90.0\n",
      "3266     65.0\n",
      "3077     95.0\n",
      "3169    139.0\n",
      "98      375.0\n",
      "2659     70.0\n",
      "3523    120.0\n",
      "931     110.0\n",
      "572     200.0\n",
      "1924     71.0\n",
      "1273    140.0\n",
      "224      99.0\n",
      "106     299.0\n",
      "1127     65.0\n",
      "845     350.0\n",
      "1413    156.0\n",
      "3705     97.0\n",
      "938     250.0\n",
      "741     600.0\n",
      "3498     95.0\n",
      "2066     85.0\n",
      "1272     85.0\n",
      "        ...  \n",
      "150     150.0\n",
      "430      55.0\n",
      "1596    299.0\n",
      "366     140.0\n",
      "1714     69.0\n",
      "2475    110.0\n",
      "1710    250.0\n",
      "1305    100.0\n",
      "749      40.0\n",
      "49      400.0\n",
      "802     120.0\n",
      "1046    240.0\n",
      "895     239.0\n",
      "3313     50.0\n",
      "2499    155.0\n",
      "2700    120.0\n",
      "3420    150.0\n",
      "2553    209.0\n",
      "942     149.0\n",
      "1769    105.0\n",
      "2005    325.0\n",
      "59       65.0\n",
      "1817     65.0\n",
      "1248    196.0\n",
      "2419    119.0\n",
      "954      36.0\n",
      "3186    110.0\n",
      "2633     90.0\n",
      "3563     50.0\n",
      "1520     90.0\n",
      "Name: price, Length: 931, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "def predict_price(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price'] = test_df['accommodates'].apply(predict_price)\n",
    "print(test_df['predicted_price'],test_df['price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets us find the mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.04425349086964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['squared_error']=np.absolute(test_df['predicted_price']-test_df['price'])\n",
    "mae=test_df['squared_error'].mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let us find the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16547.98543501601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['squared_terms']=(test_df['predicted_price']-test_df['price'])**2\n",
    "mse=test_df['squared_terms'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us create another model with bathrooms as parameters instead of accomodates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17399.74414607941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "def predict_price_model2(new_listing):\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing))\n",
    "    temp_df = temp_df.sort_values('distance')\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price']\n",
    "    predicted_price = nearest_neighbor_prices.mean()\n",
    "    return(predicted_price)\n",
    "test_df['predicted_price'] = test_df['bathrooms'].apply(predict_price_model2)\n",
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3723 entries, 574 to 1061\n",
      "Data columns (total 19 columns):\n",
      "host_response_rate      3289 non-null object\n",
      "host_acceptance_rate    3109 non-null object\n",
      "host_listings_count     3723 non-null int64\n",
      "accommodates            3723 non-null int64\n",
      "room_type               3723 non-null object\n",
      "bedrooms                3702 non-null float64\n",
      "bathrooms               3696 non-null float64\n",
      "beds                    3712 non-null float64\n",
      "price                   3723 non-null float64\n",
      "cleaning_fee            2335 non-null object\n",
      "security_deposit        1426 non-null object\n",
      "minimum_nights          3723 non-null int64\n",
      "maximum_nights          3723 non-null int64\n",
      "number_of_reviews       3723 non-null int64\n",
      "latitude                3723 non-null float64\n",
      "longitude               3723 non-null float64\n",
      "city                    3723 non-null object\n",
      "zipcode                 3714 non-null object\n",
      "state                   3723 non-null object\n",
      "dtypes: float64(6), int64(5), object(8)\n",
      "memory usage: 581.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "dc_listings = pd.read_csv('F:/education/data quest/machine learning sessions/Airbnb/dc_airbnb.csv')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates            0\n",
      "bedrooms               21\n",
      "bathrooms              27\n",
      "beds                   11\n",
      "price                   0\n",
      "cleaning_fee         1388\n",
      "security_deposit     2297\n",
      "minimum_nights          0\n",
      "maximum_nights          0\n",
      "number_of_reviews       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count']\n",
    "dc_listings = dc_listings.drop(drop_columns, axis=1)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates         0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "beds                 0\n",
      "price                0\n",
      "minimum_nights       0\n",
      "maximum_nights       0\n",
      "number_of_reviews    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_additional_columns=['cleaning_fee','security_deposit']\n",
    "dc_listings=dc_listings.drop(drop_additional_columns, axis=1)\n",
    "dc_listings=dc_listings.dropna(axis=0)\n",
    "print(dc_listings.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
      "574      -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
      "1593     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
      "3091     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
      "\n",
      "      maximum_nights  number_of_reviews  \n",
      "574        -0.016604           4.579650  \n",
      "1593       -0.016603           1.159275  \n",
      "3091       -0.016573          -0.482505  \n"
     ]
    }
   ],
   "source": [
    "normalized_listings = (dc_listings - dc_listings.mean()) / (dc_listings.std())\n",
    "normalized_listings['price']=dc_listings['price']\n",
    "print(normalized_listings.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.272543124668404\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "first_listing=normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing=normalized_listings.iloc[4][['accommodates','bathrooms']]\n",
    "first_fifth_distance=distance.euclidean(first_listing,fifth_listing)\n",
    "print(first_fifth_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  80.8  251.2   89.4   80.8   80.8   80.8  189.8  167.8  167.8  199.\n",
      "  251.2  166.6   81.   276.8   80.8   80.8   80.8  166.6   76.2  982.2\n",
      "   80.8  245.8  167.8  216.2   80.8   80.8  167.8  189.8  225.8   81.\n",
      "   81.    80.8   80.8   80.8   80.8   80.8   80.8  166.6  225.8  245.4\n",
      "  225.8   80.8   81.   167.8  135.2  167.8  167.8   80.8   80.8   80.8\n",
      "   81.    80.8   80.8   80.8  188.   135.2   92.4  145.8   80.8  251.2\n",
      "   80.8  135.2  167.8   90.4   80.8  135.2   80.8   80.8   80.8  135.2\n",
      "  166.6  223.6   80.8  135.2   80.8  135.2   80.8  106.8   80.8   80.8\n",
      "   80.8  135.2  251.2  189.8   80.8   80.8   80.8  135.2   89.4  276.8\n",
      "  199.    81.    81.    80.8   80.8  304.6  135.2  135.2  135.2  167.8\n",
      "   80.8  135.2   80.8  216.2  167.8   80.8   81.    80.8   80.8   89.4\n",
      "  225.8   80.8  189.8  238.   106.8   81.   167.8  188.   277.6  135.2\n",
      "   80.8  167.8   80.8  167.8   80.8  534.   135.2  167.8  167.8   62.8\n",
      "  167.8   80.8  135.2   80.8   80.8   80.8  166.6   80.8   90.4  251.2\n",
      "  167.8  135.2   80.8  276.8  167.8   80.8   81.    81.    90.4  135.2\n",
      "  167.8   80.8  225.8  216.2   81.   167.8  276.8  135.2   80.8   80.8\n",
      "  167.8   80.8  276.8  135.2  167.8  166.6   80.8  251.2   80.8   80.8\n",
      "  189.8   80.8  216.2  188.    80.8   80.8  216.2   80.8   80.8  135.2\n",
      "   80.8   89.4   80.8  240.6   80.8   81.    80.8  167.8  189.8  167.8\n",
      "   80.8   90.4   80.8  276.8  166.6   80.8   81.    90.4  167.8   92.4\n",
      "   80.8  135.2  135.2   80.8  167.8   80.8   80.8  167.8  216.2  240.6\n",
      "   80.8   80.8  166.6  167.8  187.8   80.8   80.8   80.8   80.8   80.8\n",
      "   80.8  135.2   80.8  167.8   80.8  304.6   81.   238.   238.   167.8\n",
      "  135.2   81.    80.8   80.8  216.2   81.   135.2   80.8  240.6  251.2\n",
      "   81.   238.   238.   167.8   80.8   80.8  380.   167.8  135.2  167.8\n",
      "   80.8   80.8   81.    80.8   80.8   80.8  188.    80.8   80.8  167.8\n",
      "   80.8  135.2  199.   135.2   80.8   80.8  276.8  167.8   80.8   80.8\n",
      "   80.8   80.8  167.8   80.8  189.8  216.2  276.8   81.   225.8   85.8\n",
      "  135.2  167.8   80.8   80.8   80.8  216.2  304.6   81.   135.2  240.6\n",
      "   80.8  225.8  135.2  276.8  135.2   80.8   80.8   80.8   80.8   81.\n",
      "   80.8   80.8   80.8   80.8   81.   135.2   80.8   80.8  251.2  167.8\n",
      "   80.8  225.8   80.8 1002.2   80.8  199.   167.8   80.8  166.6  135.2\n",
      "  198.8   80.8   80.8   62.8   81.   188.   167.8   80.8   81.    80.8\n",
      "   80.8  619.    80.8   81.    80.8  135.2   80.8   81.   135.2   80.8\n",
      "   80.8  135.2  135.2   81.    81.    81.   167.8  135.2   81.    80.8\n",
      "   81.    80.8  188.   240.6   81.   167.8  135.2   80.8   80.8  245.8\n",
      "  490.    80.8   81.   504.8   80.8  188.    80.8  276.8   80.8  145.8\n",
      "  490.   612.2   92.4   80.8  166.6   80.8  240.6   80.8  310.8   80.8\n",
      "  251.2  828.2  135.2   80.8  167.8   80.8  199.   225.8   80.8   80.8\n",
      "  167.8   81.   167.8   90.4  216.2   80.8   81.   135.2  216.2  135.2\n",
      "  199.    80.8  199.    80.8   80.8  245.8   80.8   81.    90.4  216.2\n",
      " 1002.2  225.8   80.8  167.8  108.8   80.8   80.8   80.8   80.8  276.8\n",
      "  135.2  167.8   80.8  167.8   90.4   80.8  188.    80.8   80.8  135.2\n",
      "   80.8  277.6  251.2   80.8   80.8  167.8  279.8  276.8  135.2   80.8\n",
      "   92.4  199.    92.4  238.   240.6   81.   216.2   80.8  199.    80.8\n",
      "   80.8   80.8  188.   279.8  135.2   80.8  166.6  167.8   80.8   80.8\n",
      "   81.   135.2  189.8  167.8   80.8   81.   106.8  167.8   81.    62.8\n",
      "   80.8  277.6  167.8   80.8   80.8   80.8   80.8  166.6  167.8   92.4\n",
      "   80.8  167.8   81.   135.2  167.8   81.    80.8  216.2   81.    80.8\n",
      "  380.    81.    80.8   80.8   80.8  167.8  619.   135.2  216.2   80.8\n",
      "   80.8   80.8  135.2  135.2   80.8  167.8  135.2  245.8  167.8  135.2\n",
      "   80.8  166.6  199.   135.2   80.8   80.8   81.   135.2  166.6   81.\n",
      "  188.    81.   135.2   80.8   80.8  106.8   80.8   80.8  167.8   80.8\n",
      "  167.8   80.8   80.8  189.8  166.6  199.    80.8   80.8   92.4   60.8\n",
      "   80.8  166.6   80.8   80.8  135.2  135.2  135.2  135.2   80.8  216.2\n",
      "  167.8   80.8  135.2   80.8   80.8   80.8   80.8  135.2   80.8   80.8\n",
      "   80.8   80.8   80.8  276.8   90.4  135.2   80.8   80.8  251.2   80.8\n",
      "   81.   135.2   80.8  199.   189.8   80.8   80.8  253.    81.    80.8\n",
      "   80.8  106.8   80.8   80.8   80.8   80.8  167.8   81.   167.8  135.2\n",
      "  167.8  167.8   90.4   80.8   80.8  167.8  199.   240.6  135.2   80.8\n",
      "   81.    80.8  225.8  135.2  167.8  167.8  135.2  166.6  167.8   80.8\n",
      "  225.8   80.8   80.8  207.8   81.    80.8   80.8   80.8  189.8  199.\n",
      "  135.2   80.8   80.8   80.8  207.8   80.8   80.8   80.8  135.2   80.8\n",
      "  189.8  135.2  135.2  106.8   80.8  167.8   80.8   80.8  276.8  167.8\n",
      "   90.4   80.8   81.    80.8   80.8  135.2   80.8  135.2  135.2  189.8\n",
      "   80.8  167.8  240.6  199.   166.6  251.2  167.8  135.2  199.    80.8\n",
      "  238.   251.2  135.2  279.8  167.8   80.8  167.8   80.8   80.8   80.8\n",
      "   81.   167.8   80.8  135.2  135.2   80.8  279.8  167.8  216.2   80.8\n",
      "  304.6  135.2  167.8  251.2   81.    62.8   90.4   81.   216.2  251.2\n",
      "  167.8  188.    80.8  135.2  167.8   80.8  166.6  145.8   80.8  166.6\n",
      "   81.   167.8  198.8   80.8  189.8   80.8   80.8   80.8  688.8   80.8\n",
      "  251.2  167.8   80.8   80.8   80.8  167.8   80.8   80.8   80.8   80.8\n",
      "  167.8   80.8  166.6   80.8  207.8   80.8  225.8   80.8  167.8   80.8\n",
      "  167.8   80.8  167.8  216.2  167.8  166.6   80.8  189.8  135.2   80.8\n",
      "  199.   251.2  238.    80.8  277.6  167.8   80.8   81.   167.8  135.2\n",
      "   92.4   80.8  299.8   80.8  135.2  135.2   80.8  135.2   80.8  167.8\n",
      "  240.6  166.6   80.8  296.6   90.4  383.8  167.8   80.8   80.8   80.8\n",
      "   80.8   80.8  276.8   80.8  380.    80.8  216.2  167.8   80.8   81.\n",
      "   80.8   80.8  245.4  167.8   80.8  216.2   80.8   90.4   80.8   80.8\n",
      "   80.8  167.8   81.    80.8  135.2  225.8  135.2  135.2   80.8   80.8\n",
      "  166.6   80.8  167.8  240.6   62.8  167.8   80.8  167.8  166.6   80.8\n",
      "   90.4  135.2   80.8  135.2  135.2  167.8   80.8   80.8  199.    80.8\n",
      "  167.8  167.8   80.8   80.8   80.8  445.4  167.8  167.8  167.8  225.8\n",
      "   80.8  135.2  135.2  135.2   80.8  534.   166.6   80.8   80.8  167.8\n",
      "   80.8   80.8  189.8  166.6   80.8  166.6   80.8   81.    80.8   80.8\n",
      "  167.8   80.8  550.2  216.2  189.8  216.2   81.    80.8  199.    80.8\n",
      "  135.2   85.8   80.8   80.8   80.8  167.8  240.6  199.    80.8  135.2\n",
      "   80.8   80.8  199.   304.6   81.    81.    85.8  198.8  276.8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "train_columns = ['accommodates', 'bathrooms']\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to see for only one variable acccomodates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94.2 158.8  94.2  94.2  94.2  94.2 158.8 152.6 152.6 159.6 158.8  94.2\n",
      "  55.2 159.6  94.2  94.2  94.2  94.2  55.2 453.6  94.2 158.8 152.6 152.6\n",
      "  94.2  94.2 152.6 158.8 159.6  55.2  55.2  94.2  94.2  94.2  94.2  94.2\n",
      "  94.2  94.2 159.6 263.6 159.6  94.2  55.2 152.6 129.8 152.6 152.6  94.2\n",
      "  94.2  94.2  55.2  94.2  94.2  94.2 159.6 129.8 129.8 129.8  94.2 158.8\n",
      "  94.2 129.8 152.6  94.2  94.2 129.8  94.2  94.2  94.2 129.8  94.2 287.4\n",
      "  94.2 129.8  94.2 129.8  94.2 158.8  94.2  94.2  94.2 129.8 158.8 158.8\n",
      "  94.2  94.2  94.2 129.8  94.2 159.6 159.6  55.2  55.2  94.2  94.2 263.6\n",
      " 129.8 129.8 129.8 152.6  94.2 129.8  94.2 152.6 152.6  94.2  55.2  94.2\n",
      "  94.2  94.2 159.6  94.2 158.8 152.6 158.8  55.2 152.6 159.6 297.8 129.8\n",
      "  94.2 152.6  94.2 152.6  94.2 263.6 129.8 152.6 152.6  55.2 152.6  94.2\n",
      " 129.8  94.2  94.2  94.2  94.2  94.2  94.2 158.8 152.6 129.8  94.2 159.6\n",
      " 152.6  94.2  55.2  55.2  94.2 129.8 152.6  94.2 159.6 152.6  55.2 152.6\n",
      " 159.6 129.8  94.2  94.2 152.6  94.2 159.6 129.8 152.6  94.2  94.2 158.8\n",
      "  94.2  94.2 158.8  94.2 152.6 159.6  94.2  94.2 152.6  94.2  94.2 129.8\n",
      "  94.2  94.2  94.2 152.6  94.2  55.2  94.2 152.6 158.8 152.6  94.2  94.2\n",
      "  94.2 159.6  94.2  94.2  55.2  94.2 152.6 129.8  94.2 129.8 129.8  94.2\n",
      " 152.6  94.2  94.2 152.6 152.6 152.6  94.2  94.2  94.2 152.6 129.8  94.2\n",
      "  94.2  94.2  94.2  94.2  94.2 129.8  94.2 152.6  94.2 263.6  55.2 152.6\n",
      " 152.6 152.6 129.8  55.2  94.2  94.2 152.6  55.2 129.8  94.2 152.6 158.8\n",
      "  55.2 152.6 152.6 152.6  94.2  94.2 159.6 152.6 129.8 152.6  94.2  94.2\n",
      "  55.2  94.2  94.2  94.2 159.6  94.2  94.2 152.6  94.2 129.8 159.6 129.8\n",
      "  94.2  94.2 159.6 152.6  94.2  94.2  94.2  94.2 152.6  94.2 158.8 152.6\n",
      " 159.6  55.2 159.6  94.2 129.8 152.6  94.2  94.2  94.2 152.6 263.6  55.2\n",
      " 129.8 152.6  94.2 159.6 129.8 159.6 129.8  94.2  94.2  94.2  94.2  55.2\n",
      "  94.2  94.2  94.2  94.2  55.2 129.8  94.2  94.2 158.8 152.6  94.2 159.6\n",
      "  94.2 611.6  94.2 159.6 152.6  94.2  94.2 129.8 297.8  94.2  94.2  55.2\n",
      "  55.2 159.6 152.6  94.2  55.2  94.2  94.2 297.8  94.2  55.2  94.2 129.8\n",
      "  94.2  55.2 129.8  94.2  94.2 129.8 129.8  55.2  55.2  55.2 152.6 129.8\n",
      "  55.2  94.2  55.2  94.2 159.6 152.6  55.2 152.6 129.8  94.2  94.2 158.8\n",
      " 534.6  94.2  55.2 287.4  94.2 159.6  94.2 159.6  94.2 129.8 534.6 159.6\n",
      " 129.8  94.2  94.2  94.2 152.6  94.2 312.8  94.2 158.8 742.  129.8  94.2\n",
      " 152.6  94.2 159.6 159.6  94.2  94.2 152.6  55.2 152.6  94.2 152.6  94.2\n",
      "  55.2 129.8 152.6 129.8 159.6  94.2 159.6  94.2  94.2 158.8  94.2  55.2\n",
      "  94.2 152.6 611.6 159.6  94.2 152.6  94.2  94.2  94.2  94.2  94.2 159.6\n",
      " 129.8 152.6  94.2 152.6  94.2  94.2 159.6  94.2  94.2 129.8  94.2 297.8\n",
      " 158.8  94.2  94.2 152.6 297.8 159.6 129.8  94.2 129.8 159.6 129.8 152.6\n",
      " 152.6  55.2 152.6  94.2 159.6  94.2  94.2  94.2 159.6 297.8 129.8  94.2\n",
      "  94.2 152.6  94.2  94.2  55.2 129.8 158.8 152.6  94.2  55.2 158.8 152.6\n",
      "  55.2  55.2  94.2 297.8 152.6  94.2  94.2  94.2  94.2  94.2 152.6 129.8\n",
      "  94.2 152.6  55.2 129.8 152.6  55.2  94.2 152.6  55.2  94.2 159.6  55.2\n",
      "  94.2  94.2  94.2 152.6 297.8 129.8 152.6  94.2  94.2  94.2 129.8 129.8\n",
      "  94.2 152.6 129.8 158.8 152.6 129.8  94.2  94.2 159.6 129.8  94.2  94.2\n",
      "  55.2 129.8  94.2  55.2 159.6  55.2 129.8  94.2  94.2 158.8  94.2  94.2\n",
      " 152.6  94.2 152.6  94.2  94.2 158.8  94.2 159.6  94.2  94.2 129.8  55.2\n",
      "  94.2  94.2  94.2  94.2 129.8 129.8 129.8 129.8  94.2 152.6 152.6  94.2\n",
      " 129.8  94.2  94.2  94.2  94.2 129.8  94.2  94.2  94.2  94.2  94.2 159.6\n",
      "  94.2 129.8  94.2  94.2 158.8  94.2  55.2 129.8  94.2 159.6 158.8  94.2\n",
      "  94.2 287.4  55.2  94.2  94.2 158.8  94.2  94.2  94.2  94.2 152.6  55.2\n",
      " 152.6 129.8 152.6 152.6  94.2  94.2  94.2 152.6 159.6 152.6 129.8  94.2\n",
      "  55.2  94.2 159.6 129.8 152.6 152.6 129.8  94.2 152.6  94.2 159.6  94.2\n",
      "  94.2 263.6  55.2  94.2  94.2  94.2 158.8 159.6 129.8  94.2  94.2  94.2\n",
      " 263.6  94.2  94.2  94.2 129.8  94.2 158.8 129.8 129.8 158.8  94.2 152.6\n",
      "  94.2  94.2 159.6 152.6  94.2  94.2  55.2  94.2  94.2 129.8  94.2 129.8\n",
      " 129.8 158.8  94.2 152.6 152.6 159.6  94.2 158.8 152.6 129.8 159.6  94.2\n",
      " 152.6 158.8 129.8 297.8 152.6  94.2 152.6  94.2  94.2  94.2  55.2 152.6\n",
      "  94.2 129.8 129.8  94.2 297.8 152.6 152.6  94.2 263.6 129.8 152.6 158.8\n",
      "  55.2  55.2  94.2  55.2 152.6 158.8 152.6 159.6  94.2 129.8 152.6  94.2\n",
      "  94.2 129.8  94.2  94.2  55.2 152.6 297.8  94.2 158.8  94.2  94.2  94.2\n",
      " 158.8  94.2 158.8 152.6  94.2  94.2  94.2 152.6  94.2  94.2  94.2  94.2\n",
      " 152.6  94.2  94.2  94.2 263.6  94.2 159.6  94.2 152.6  94.2 152.6  94.2\n",
      " 152.6 152.6 152.6  94.2  94.2 158.8 129.8  94.2 159.6 158.8 152.6  94.2\n",
      " 297.8 152.6  94.2  55.2 152.6 129.8 129.8  94.2 312.8  94.2 129.8 129.8\n",
      "  94.2 129.8  94.2 152.6 152.6  94.2  94.2 287.4  94.2 297.8 152.6  94.2\n",
      "  94.2  94.2  94.2  94.2 159.6  94.2 159.6  94.2 152.6 152.6  94.2  55.2\n",
      "  94.2  94.2 263.6 152.6  94.2 152.6  94.2  94.2  94.2  94.2  94.2 152.6\n",
      "  55.2  94.2 129.8 159.6 129.8 129.8  94.2  94.2  94.2  94.2 152.6 152.6\n",
      "  55.2 152.6  94.2 152.6  94.2  94.2  94.2 129.8  94.2 129.8 129.8 152.6\n",
      "  94.2  94.2 159.6  94.2 152.6 152.6  94.2  94.2  94.2 453.6 152.6 152.6\n",
      " 152.6 159.6  94.2 129.8 129.8 129.8  94.2 263.6  94.2  94.2  94.2 152.6\n",
      "  94.2  94.2 158.8  94.2  94.2  94.2  94.2  55.2  94.2  94.2 152.6  94.2\n",
      " 341.2 152.6 158.8 152.6  55.2  94.2 159.6  94.2 129.8  94.2  94.2  94.2\n",
      "  94.2 152.6 152.6 159.6  94.2 129.8  94.2  94.2 159.6 263.6  55.2  55.2\n",
      "  94.2 297.8 159.6]\n",
      "18546.832901023892 136.18675743633773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "train_columns = ['accommodates']\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "two_features_mse=mean_squared_error(test_df['price'],predictions)\n",
    "two_features_rmse=two_features_mse**(0.5)\n",
    "print(two_features_mse,two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thus we see that when we trained 2 univariant models with accomodation variable in the 1st one and bathrooms in the 2nd. We observe that traning the models with both vairiables combined yielded to a lower mean squared error and root mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Now let us train the model through four variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13322.432400455064 115.42284176217056\n"
     ]
    }
   ],
   "source": [
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features],train_df['price'])\n",
    "four_predictions=knn.predict(test_df[features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "four_mse=mean_squared_error(test_df['price'],four_predictions)\n",
    "four_rmse=four_mse**(0.5)\n",
    "print(four_mse,four_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As the features increased we see lower error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us experiment and use all the features except price value and we see that selecting all or lots of features doesn't  guarentee better effeciency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accommodates', 'bedrooms', 'bathrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews']\n",
      "15455.275631399316 115.42284176217056\n"
     ]
    }
   ],
   "source": [
    "features=train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "print(features)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "knn.fit(train_df[features],train_df['price'])\n",
    "all_features_predictions=knn.predict(test_df[features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "all_features_mse=mean_squared_error(test_df['price'],all_features_predictions)\n",
    "all_features_rmse=four_mse**(0.5)\n",
    "print(all_features_mse,all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking all the parameters that are not dependant on data like K  (Hyper parameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[25897.758816837315, 14829.874004550626, 14507.932625458221, 14633.708333333334, 13322.432400455064]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "hyper_params=[i for i in range(1,6)]\n",
    "features=['accommodates','bedrooms','bathrooms','number_of_reviews']\n",
    "print(hyper_params)\n",
    "mse_values=[]\n",
    "for x in hyper_params:\n",
    "    knn=KNeighborsRegressor(n_neighbors=x,algorithm='brute')\n",
    "    knn.fit(train_df[features],train_df['price'])\n",
    "    predictions=knn.predict(test_df[features])\n",
    "    mse=mean_squared_error(test_df['price'],predictions)\n",
    "    mse_values.append(mse)\n",
    "print(mse_values)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let us check for more k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25897.758816837315, 14829.874004550626, 14507.932625458221, 14633.708333333334, 13322.432400455064, 12903.254708633547, 13126.052448283068, 13380.156054465302, 13654.969325411872, 14103.407940841866, 14133.00453182147, 14372.550246492225, 14475.569972602003, 14437.902527222492, 14520.491032739223, 14620.297741574232, 14708.674157878368, 14665.33477647158, 14639.924246578365, 14572.638831058024]\n",
      "12903.254708633547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "hyper_params=[i for i in range(1,21)]\n",
    "features=['accommodates','bedrooms','bathrooms','number_of_reviews']\n",
    "mse_values=[]\n",
    "for x in hyper_params:\n",
    "    knn=KNeighborsRegressor(n_neighbors=x,algorithm='brute')\n",
    "    knn.fit(train_df[features],train_df['price'])\n",
    "    predictions=knn.predict(test_df[features])\n",
    "    mse=mean_squared_error(test_df['price'],predictions)\n",
    "    mse_values.append(mse)\n",
    "print(mse_values)  \n",
    "print(min(mse_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of k depency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1PH/ABTnBQKF/OG1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24cd79ccf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']\n",
    "hyper_params = [x for x in range(1, 21)]\n",
    "mse_values = list()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "plt.scatter(hyper_params,mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the lowest is at k=6 hence it is the optimal value that should be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the previous experimental attempt we used all parameters except 'price' and saw the output which was not a better effeciency than only 4 parameters that we choose before.Hence we concluded that effeciency doesn't increase on increasing features instead perfect features are required.\n",
    "In hyperparameter optimization we learned that an optimum k can be found by grid search method. Now let us experiment to find an optimal k for all the parameteres except 'price' to see if the effeciency is improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEt9JREFUeJzt3H+MXWWdx/H3d1skjQoV2rBQulsM2ARWF2SWNKIuLptt\nJcZ2DTHdGKmRQBTWiHFrqCbq/iVYV7JsVjZsIPwIERArkF0Jopj1r5adAlIKVOqioUOF8rNu7CKt\n3/3jPqO388wwd+beuWcu9/1KbubMc85zz3PPnHs+9zzPcycyE0mS2v1R0w2QJM0/hoMkqWI4SJIq\nhoMkqWI4SJIqhoMkqWI4SJIqhoMkqWI4SJIqC5tuwGwtWbIkV6xY0XQzJGmgbN++/fnMXDrddgMb\nDitWrGB0dLTpZkjSQImIX3aynd1KkqSK4SBJqhgOkqSK4SBJqhgOkqTKwM5Wmo07Hxpj8727eObl\nA5yweBEbV69k3RnLmm6WJM07QxMOdz40xqYtOzjw2iEAxl4+wKYtOwAMCEmaYGi6lTbfu+v3wTDu\nwGuH2HzvroZaJEnz19CEwzMvH5hRuSQNs6EJhxMWL5pRuSQNs6EJh42rV7LoiAWHlS06YgEbV69s\nqEWSNH8NzYD0+KCzs5UkaXpDEw7QCgjDQJKmNzTdSpKkzhkOkqSK4SBJqhgOkqSK4SBJqhgOkqSK\n4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqSK4SBJ\nqhgOkqSK4SBJqhgOkqSK4SBJqhgOkqTKtOEQEcsj4scR8VhE7IyIz5byzRHxREQ8EhHfi4jFbXU2\nRcTuiNgVEavbys+MiB1l3dUREaX8yIi4rZRvi4gVvX+pkqROdXLncBD4fGaeCqwCLo2IU4H7gD/L\nzHcBPwM2AZR164HTgDXAtyJiQXmua4CLgFPKY00pvxB4KTNPBq4CruzBa5MkzdK04ZCZezPzwbL8\na+BxYFlm/iAzD5bNtgInluW1wK2Z+WpmPgXsBs6KiOOBozJza2YmcBOwrq3OjWX5DuDc8bsKSVL/\nzWjMoXT3nAFsm7Dqk8A9ZXkZ8HTbuj2lbFlZnlh+WJ0SOK8Ax06y/4sjYjQiRvft2zeTpkuSZqDj\ncIiItwDfBS7LzP1t5V+i1fV0S++bd7jMvDYzRzJzZOnSpXO9O0kaWh2FQ0QcQSsYbsnMLW3lnwA+\nBHysdBUBjAHL26qfWMrG+EPXU3v5YXUiYiFwNPDCDF+LJKlHOpmtFMB1wOOZ+c228jXAF4APZ+Zv\n2qrcDawvM5BOojXw/EBm7gX2R8Sq8pwXAHe11dlQls8H7m8LG0lSny3sYJuzgY8DOyLi4VL2ReBq\n4EjgvjJ2vDUzP5WZOyPiduAxWt1Nl2bmoVLvEuAGYBGtMYrxcYrrgJsjYjfwIq3ZTpKkhsSgfkAf\nGRnJ0dHRppshSQMlIrZn5sh02/kNaUlSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUM\nB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lS\nxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQJFUMB0lSxXCQ\nJFUMB0lSxXCQJFWmDYeIWB4RP46IxyJiZ0R8tpQfExH3RcST5efb2upsiojdEbErIla3lZ8ZETvK\nuqsjIkr5kRFxWynfFhErev9SJUmd6uTO4SDw+cw8FVgFXBoRpwKXAz/KzFOAH5XfKevWA6cBa4Bv\nRcSC8lzXABcBp5THmlJ+IfBSZp4MXAVc2YPXJkmapWnDITP3ZuaDZfnXwOPAMmAtcGPZ7EZgXVle\nC9yama9m5lPAbuCsiDgeOCozt2ZmAjdNqDP+XHcA547fVUiS+m9GYw6lu+cMYBtwXGbuLat+BRxX\nlpcBT7dV21PKlpXlieWH1cnMg8ArwLEzaZskqXc6DoeIeAvwXeCyzNzfvq7cCWSP2zZZGy6OiNGI\nGN23b99c706ShlZH4RARR9AKhlsyc0spfrZ0FVF+PlfKx4DlbdVPLGVjZXli+WF1ImIhcDTwwsR2\nZOa1mTmSmSNLly7tpOmSpFnoZLZSANcBj2fmN9tW3Q1sKMsbgLvayteXGUgn0Rp4fqB0Qe2PiFXl\nOS+YUGf8uc4H7i93I5KkBizsYJuzgY8DOyLi4VL2ReAK4PaIuBD4JfBRgMzcGRG3A4/Rmul0aWYe\nKvUuAW4AFgH3lAe0wufmiNgNvEhrtpMkqSExqB/QR0ZGcnR0tOlmSNJAiYjtmTky3XZ+Q1qSVDEc\nJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkV\nw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GS\nVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVDEcJEkVw0GSVJk2HCLi+oh4LiIe\nbSs7PSK2RsTDETEaEWe1rdsUEbsjYldErG4rPzMidpR1V0dElPIjI+K2Ur4tIlb09iVKkmaqkzuH\nG4A1E8q+DvxjZp4OfLn8TkScCqwHTit1vhURC0qda4CLgFPKY/w5LwReysyTgauAK2f7YiRJvTFt\nOGTmT4AXJxYDR5Xlo4FnyvJa4NbMfDUznwJ2A2dFxPHAUZm5NTMTuAlY11bnxrJ8B3Du+F2FJKkZ\nC2dZ7zLg3oj4Bq2AeU8pXwZsbdtuTyl7rSxPLB+v8zRAZh6MiFeAY4HnZ9k2SVKXZjsg/Wngc5m5\nHPgccF3vmjS1iLi4jHGM7tu3rx+7lKShNNtw2ABsKcvfAcYHpMeA5W3bnVjKxsryxPLD6kTEQlrd\nVC9MttPMvDYzRzJzZOnSpbNsuiRpOrMNh2eAvyzLfwU8WZbvBtaXGUgn0Rp4fiAz9wL7I2JVGU+4\nALirrc6Gsnw+cH8Zl5AkNWTaMYeI+DZwDrAkIvYAX6E16+ifyyf9/wMuBsjMnRFxO/AYcBC4NDMP\nlae6hNbMp0XAPeUBrS6pmyNiN62B7/U9eWWSpFmLQf2QPjIykqOjo003Q5IGSkRsz8yR6bbzG9KS\npIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrh\nIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmq\nGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpIrhIEmqGA6SpMq04RAR10fE\ncxHx6ITyz0TEExGxMyK+3la+KSJ2R8SuiFjdVn5mROwo666OiCjlR0bEbaV8W0Ss6N3LkyTNRid3\nDjcAa9oLIuIDwFrgzzPzNOAbpfxUYD1wWqnzrYhYUKpdA1wEnFIe4895IfBSZp4MXAVc2cXrkST1\nwLThkJk/AV6cUPxp4IrMfLVs81wpXwvcmpmvZuZTwG7grIg4HjgqM7dmZgI3Aeva6txYlu8Azh2/\nq5AkNWO2Yw7vAN5XuoH+KyL+opQvA55u225PKVtWlieWH1YnMw8CrwDHTrbTiLg4IkYjYnTfvn2z\nbLokaTqzDYeFwDHAKmAjcHs/Pu1n5rWZOZKZI0uXLp3r3UnS0JptOOwBtmTLA8DvgCXAGLC8bbsT\nS9lYWZ5YTnudiFgIHA28MMt2SZJ6YLbhcCfwAYCIeAfwJuB54G5gfZmBdBKtgecHMnMvsD8iVpU7\njAuAu8pz3Q1sKMvnA/eXcQlJUkMWTrdBRHwbOAdYEhF7gK8A1wPXl+mtvwU2lAv6zoi4HXgMOAhc\nmpmHylNdQmvm0yLgnvIAuA64OSJ20xr4Xt+blyZJmq0Y1A/pIyMjOTo62nQzJGmgRMT2zByZbju/\nIS1JqhgOkqSK4SBJqkw7IK35486Hxth87y6eefkAJyxexMbVK1l3xrLpK75B9i+pfwyHAXHnQ2Ns\n2rKDA6+1Jn+NvXyATVt2AHR8ge7m4t6L/UsaHHYrDYjN9+76/YV53IHXDrH53l0d1R+/uI+9fIDk\nDxf3Ox8am7ZuL/YvabAYDgPimZcPzKh8om4v7t3uX9JgMRwGxAmLF82ofKJuL+7d7l/SYDEcBsTG\n1StZdMSCw8oWHbGAjatXdlS/24t7t/uXNFgMhwGx7oxlfO0j72TZ4kUEsGzxIr72kXd2PBjc7cW9\n2/1LGiz++4wh4lRUqTtNv4d6sf9O/32GU1mHyLozlg10GDT9xtRwG7bp5HYraSB0OxV3/DnOvuJ+\nTrr8Pzn7ivtnVFcatunkhoMGQtNvTGnYppPbrdRHw94t0s3rn8s35jD9DYZdN+fgCYsXMTbJ+dbP\n6eTd7H+mvHPok2H/5Nrt62/6ex5qvluu2/13ew4O23Ryw2EGujk5h/3fT3T7+pt+Yw67psd8erH/\nbs/BYZtObrdSh7qdKTDsn1y7ff3jx3i2XQIbV6887O8HfolvJrrtluv2/dOLbsFevAe7mfHX7Tnc\n7f5nynDoULcnZ7/7C+ebXrz+pt+Ygz5mNMhjPr24sM+H9+AgTSc3HDrU7ck57J9c58Pr7+aNOR/+\nZXmTc+TfCIOx8+EcHCSOOXSo2z7rYf/3E4P++nsxZtRkn/ugj/n0YjB20M/BfvPOoUO9+NQxSLeU\nc2GQX3+3n3yb7nMf9DGfXnQLjj/PoJ6D/WY4dKhXJ6cGU7fdGk1f3N8IYz5e2PvLcJgBT87h1e0n\n36Yv7vOhv933z2BxzEHqQLf91U33udvfrpnyX3ZLfTBxzAFaF/eZXKAHfSqt5gf/Zbc0j9jnrkFj\nOEh94sVdg8QxB0lSxXCQJFUMB0lSxXCQJFUMB0lSZWC/5xAR+4BfNt2OKSwBnm+6Ea/D9nXH9nVn\nvrcP5n8bu2nfn2bm0uk2GthwmM8iYrSTL5k0xfZ1x/Z1Z763D+Z/G/vRPruVJEkVw0GSVDEc5sa1\nTTdgGravO7avO/O9fTD/2zjn7XPMQZJU8c5BklQxHGYpIpZHxI8j4rGI2BkRn51km3Mi4pWIeLg8\nvtznNv4iInaUfVf/3zxaro6I3RHxSES8u49tW9l2XB6OiP0RcdmEbfp6/CLi+oh4LiIebSs7JiLu\ni4gny8+3TVF3TUTsKsfy8j62b3NEPFH+ft+LiMVT1H3dc2EO2/fViBhr+xueN0Xdpo7fbW1t+0VE\nPDxF3X4cv0mvKY2dg5npYxYP4Hjg3WX5rcDPgFMnbHMO8B8NtvEXwJLXWX8ecA8QwCpgW0PtXAD8\nitb868aOH/B+4N3Ao21lXwcuL8uXA1dO0f6fA28H3gT8dOK5MIft+xtgYVm+crL2dXIuzGH7vgr8\nQwd//0aO34T1/wR8ucHjN+k1palz0DuHWcrMvZn5YFn+NfA4MGj/j3ktcFO2bAUWR8TxDbTjXODn\nmdnolxoz8yfAixOK1wI3luUbgXWTVD0L2J2Z/5OZvwVuLfXmvH2Z+YPMPFh+3Qqc2Ov9dmqK49eJ\nxo7fuIgI4KPAt3u93069zjWlkXPQcOiBiFgBnAFsm2T1e8ot/z0RcVpfGwYJ/DAitkfExZOsXwY8\n3fb7HpoJuPVM/aZs8vgBHJeZe8vyr4DjJtlmvhzHT9K6E5zMdOfCXPpM+RteP0WXyHw4fu8Dns3M\nJ6dY39fjN+Ga0sg5aDh0KSLeAnwXuCwz909Y/SDwJ5n5LuBfgDv73Lz3ZubpwAeBSyPi/X3e/7Qi\n4k3Ah4HvTLK66eN3mGzdv8/L6X0R8SXgIHDLFJs0dS5cQ6ur43RgL62um/no73j9u4a+Hb/Xu6b0\n8xw0HLoQEUfQ+iPekplbJq7PzP2Z+b9l+fvAERGxpF/ty8yx8vM54Hu0bj3bjQHL234/sZT10weB\nBzPz2Ykrmj5+xbPjXW3l53OTbNPocYyITwAfAj5WLh6VDs6FOZGZz2bmocz8HfDvU+y36eO3EPgI\ncNtU2/Tr+E1xTWnkHDQcZqn0UV4HPJ6Z35ximz8u2xERZ9E63i/0qX1vjoi3ji/TGrh8dMJmdwMX\nlFlLq4BX2m5f+2XKT2xNHr82dwMbyvIG4K5Jtvlv4JSIOKncCa0v9eZcRKwBvgB8ODN/M8U2nZwL\nc9W+9jGsv51iv40dv+KvgScyc89kK/t1/F7nmtLMOTiXo+9v5AfwXlq3d48AD5fHecCngE+Vbf4e\n2Elr5sBW4D19bN/by35/WtrwpVLe3r4A/pXWLIcdwEifj+GbaV3sj24ra+z40QqpvcBrtPpsLwSO\nBX4EPAn8EDimbHsC8P22uufRml3y8/Fj3af27abV1zx+Dv7bxPZNdS70qX03l3PrEVoXq+Pn0/Er\n5TeMn3Nt2zZx/Ka6pjRyDvoNaUlSxW4lSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAkVQwHSVLFcJAk\nVf4fRyfhyS1OZuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24cd803b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper_params = [x for x in range(1,21)]\n",
    "mse_values = list()\n",
    "features=train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "for x in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=x, algorithm='brute')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    mse_values.append(mse)\n",
    "plt.scatter(hyper_params,mse_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us try again the previous model with all features except 'price'with k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accommodates', 'bedrooms', 'bathrooms', 'beds', 'minimum_nights', 'maximum_nights', 'number_of_reviews']\n",
      "14917.095278725825 115.42284176217056\n"
     ]
    }
   ],
   "source": [
    "features=train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "print(features)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=2, algorithm='brute')\n",
    "knn.fit(train_df[features],train_df['price'])\n",
    "all_features_predictions=knn.predict(test_df[features])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "all_features_mse=mean_squared_error(test_df['price'],all_features_predictions)\n",
    "all_features_rmse=four_mse**(0.5)\n",
    "print(all_features_mse,all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we see a better result than the previous where hyperparameter optimization wasn't done,but still this result is not the best that we obtained when we used only 4 parameters with k=6 hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets do hyperparameter optimization to model with only two features and three features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: 15587.77528125395} {5: 13285.701069397044}\n"
     ]
    }
   ],
   "source": [
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "\n",
    "two_mse_values = list()\n",
    "two_hyp_mse = dict()\n",
    "three_hyp_mse = dict()\n",
    "three_mse_values = list()\n",
    "for x in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=x, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)\n",
    "    \n",
    "temp=two_mse_values[0]\n",
    "temp_key=1\n",
    "\n",
    "for key,val in enumerate(two_mse_values):\n",
    "#when enumerate is used key starts from 0    \n",
    "    if (val<temp):\n",
    "        temp=val\n",
    "        temp_key=key+1\n",
    "two_hyp_mse[temp_key] = temp  \n",
    "\n",
    "for x in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=x, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values.append(mse)\n",
    "    \n",
    "    \n",
    "temp=three_mse_values[0]\n",
    "temp_key=1\n",
    "for key,val in enumerate(three_mse_values):\n",
    "#when enumerate is used key starts from 0    \n",
    "    if (val<temp):\n",
    "        temp=val\n",
    "        temp_key=key+1\n",
    "three_hyp_mse[temp_key] = temp      \n",
    "    \n",
    "print(two_hyp_mse,three_hyp_mse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thus we obtain k=6 for 2 feature model and k=5 for three feature model respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a matter of fact 13285 is the least error that we have found in this entire project till now which is only by using three features and hyperparameter optimization.(Even lesser error than 4 features model + hp optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us use holdout validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dc_listings = pd.read_csv(\"dc_airbnb.csv\")\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')'''\n",
    "\n",
    "shuffled_index = np.random.permutation(dc_listings.index)\n",
    "dc_listings = dc_listings.reindex(shuffled_index)\n",
    "\n",
    "split_one=dc_listings.iloc[0:1862]\n",
    "split_two=dc_listings.iloc[1862:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.72468326695143 140.8295579907386\n",
      "129.277120628845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# holdout validation is when training and testing set is 50% and then both gets exchanges and we find the mean of errors.\n",
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "# 1st case\n",
    "knn=KNeighborsRegressor(algorithm='auto',n_neighbors=5)\n",
    "knn.fit(train_one[['accommodates']],train_one['price'])\n",
    "predictions=knn.predict(test_one[['accommodates']])\n",
    "iteration_one_mse=mean_squared_error(test_one['price'],predictions)\n",
    "iteration_one_rmse=iteration_one_mse**(0.5)\n",
    "#2nd case\n",
    "knn=KNeighborsRegressor(algorithm='auto',n_neighbors=5)\n",
    "knn.fit(train_two[['accommodates']],train_two['price'])\n",
    "predictions=knn.predict(test_two[['accommodates']])\n",
    "iteration_two_mse=mean_squared_error(test_two['price'],predictions)\n",
    "iteration_two_rmse=iteration_two_mse**(0.5)\n",
    "\n",
    "avg_rmse=np.mean([iteration_two_rmse,iteration_one_rmse])\n",
    "\n",
    "print(iteration_one_rmse,iteration_two_rmse)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- fold cross validation method (dividing data into k folds and alternately chosing 1 fold as the test data with rest as the train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    745\n",
      "1.0    745\n",
      "4.0    744\n",
      "3.0    744\n",
      "5.0    693\n",
      "Name: fold, dtype: int64\n",
      "\n",
      " Num of missing values:  0\n"
     ]
    }
   ],
   "source": [
    "dc_listings.loc[dc_listings.index[0:745], \"fold\"] = 1\n",
    "dc_listings.loc[dc_listings.index[745:1490], \"fold\"] = 2\n",
    "dc_listings.loc[dc_listings.index[1490:2234], \"fold\"] = 3\n",
    "dc_listings.loc[dc_listings.index[2234:2978], \"fold\"] = 4\n",
    "dc_listings.loc[dc_listings.index[2978:3723], \"fold\"] = 5\n",
    "\n",
    "print(dc_listings['fold'].value_counts())\n",
    "print(\"\\n Num of missing values: \", dc_listings['fold'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.45600004887692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_df=dc_listings[dc_listings['fold']!=1]\n",
    "test_df=dc_listings[dc_listings['fold']==1]\n",
    "\n",
    "train_columns = ['accommodates']\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='auto')\n",
    "knn.fit(train_df[train_columns], train_df['price'])\n",
    "predictions = knn.predict(test_df[train_columns])\n",
    "\n",
    "iteration_one_mse=mean_squared_error(test_df['price'],predictions)\n",
    "iteration_one_rmse=iteration_one_mse**(0.5)\n",
    "print(iteration_one_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let us do the rest of task by defning a func train_and_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neil pradhan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105.45600004887692, 140.22399894167413, 153.35961918216583, 131.31358347216434, 114.07989529633392]\n",
      "128.88661938824302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "fold_ids = [1,2,3,4,5]\n",
    "def train_and_validate(df,folds):\n",
    "    rmses=[]\n",
    "    for x in folds:\n",
    "        train_df=df[df['fold']!=x]\n",
    "        test_df=df[df['fold']==x]\n",
    "        train_columns = ['accommodates']\n",
    "        knn = KNeighborsRegressor(n_neighbors=5, algorithm='auto')\n",
    "        knn.fit(train_df[train_columns], train_df['price'])\n",
    "        test_df['predicted_price'] = knn.predict(test_df[train_columns])\n",
    "        mse=mean_squared_error(test_df['price'],test_df['predicted_price'])\n",
    "        rmse=mse**(0.5)\n",
    "        rmses.append(rmse)\n",
    "    avg_rmse=np.mean(rmses)    \n",
    "    return rmses\n",
    "k=train_and_validate(dc_listings,fold_ids)\n",
    "print(k)\n",
    "avg_rmse=np.mean(k)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.57324706 108.34713663 137.74874572 108.02754316 139.79990703]\n",
      "128.49931592107862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "knn=KNeighborsRegressor()\n",
    "mses=cross_val_score(knn,dc_listings[['accommodates']],dc_listings['price'],cv=kf,scoring=\"neg_mean_squared_error\")\n",
    "rmses = np.sqrt(np.absolute(mses))\n",
    "avg_rmse = np.mean(rmses)\n",
    "print(rmses)\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the right k is very essential. when k=2(hold out validation) where as when k=n=(no of observations) LOOCV\n",
    "let us experiment with different k values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 folds:  avg RMSE:  123.17064375729854 std RMSE:  4.2689330359893765\n",
      "5 folds:  avg RMSE:  128.49931592107862 std RMSE:  16.97893890878854\n",
      "7 folds:  avg RMSE:  127.97513377042846 std RMSE:  20.49543527053172\n",
      "9 folds:  avg RMSE:  123.61872669423639 std RMSE:  24.383915795024848\n",
      "10 folds:  avg RMSE:  127.14768452083968 std RMSE:  24.12971080464867\n",
      "11 folds:  avg RMSE:  127.6162429896584 std RMSE:  29.36740885935232\n",
      "13 folds:  avg RMSE:  122.74835655496307 std RMSE:  32.37835226566323\n",
      "15 folds:  avg RMSE:  122.75764540123978 std RMSE:  32.89326016096263\n",
      "17 folds:  avg RMSE:  123.00505315300288 std RMSE:  35.48871237937227\n",
      "19 folds:  avg RMSE:  122.14821235192935 std RMSE:  35.17365639938169\n",
      "21 folds:  avg RMSE:  121.10942246881532 std RMSE:  37.115747446720576\n",
      "23 folds:  avg RMSE:  124.93985894775318 std RMSE:  39.278718711279566\n",
      "all_avg_rmses= [123.17064375729854, 128.49931592107862, 127.97513377042846, 123.61872669423639, 127.14768452083968, 127.6162429896584, 122.74835655496307, 122.75764540123978, 123.00505315300288, 122.14821235192935, 121.10942246881532, 124.93985894775318]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]\n",
    "l=[]\n",
    "for fold in num_folds:\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    l.append(avg_rmse)\n",
    "    std_rmse = np.std(rmses)\n",
    "    print(str(fold), \"folds: \", \"avg RMSE: \", str(avg_rmse), \"std RMSE: \", str(std_rmse))\n",
    "print(\"all_avg_rmses=\",l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
